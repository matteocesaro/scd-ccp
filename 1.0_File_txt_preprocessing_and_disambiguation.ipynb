{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.0_File_txt_preprocessing_and_disambiguation_Github.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Semantic change detection task 2021-2022<br/>\n","\n","##1.0_File_txt_Preprocessing and disambiguation<br/>\n","\n","Matteo Cesaro - matteo.t.cesaro@gmail.com<br/>"],"metadata":{"id":"sIG5lkQCdR9M"}},{"cell_type":"markdown","source":["# Mounting drive and libraries"],"metadata":{"id":"wwxDr7Yyzhir"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEYSly_NBd5h","executionInfo":{"status":"ok","timestamp":1646305612813,"user_tz":-60,"elapsed":4016,"user":{"displayName":"Matteo Cesaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16924188894918542260"}},"outputId":"fdfbf4a7-6f13-4d2b-a600-aa843e945229"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"qrB22atPfJgY"},"source":["## Installing GENRE for disambiguation\n","\n","https://github.com/facebookresearch/GENRE"]},{"cell_type":"code","metadata":{"id":"KzQT3teYVNRY"},"source":["!git clone --branch fixing_prefix_allowed_tokens_fn https://github.com/nicola-decao/fairseq\n","%cd fairseq\n","!pip install --editable ./"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxUXCpudHEQn"},"source":["!pip install --upgrade git+git://github.com/facebookresearch/GENRE.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSO4MBXlL08m"},"source":["!pip install unidecode\n","!pip install requests\n","!pip install kilt\n","#!pip install fairseq\n","!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1zu8qEZDq9-"},"source":["# load the prefix tree (trie)\n","with open(\"/.../kilt_titles_trie_dict.pkl\", \"rb\") as f:\n","    trie = Trie.load_from_dict(pickle.load(f))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccZCOFHiJQP4","executionInfo":{"status":"ok","timestamp":1646305784547,"user_tz":-60,"elapsed":40285,"user":{"displayName":"Matteo Cesaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16924188894918542260"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a92aa4ea-27b4-4961-8fde-6e02104df775"},"source":["model = GENRE.from_pretrained(\"/.../fairseq_entity_disambiguation_blink\").eval()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["1042301B [00:00, 2294631.45B/s]\n","456318B [00:00, 1372051.52B/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"02Gt2YMfN8tA"},"source":["Parameters\n"]},{"cell_type":"code","metadata":{"id":"2eeQ5iYH7ly3"},"source":[" stop_words = set(stopwords.words('english'))\n"," word_phrases_target = [\"(climate) (change)\", \"(global) (warming)\", \"(renewable) (energy)\", \"(carbon) (footprint)\"]\n"," words_to_disambiguate = [\"climate\", \"warming\", \"temperature\", \"emission\", \"pollution\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Libraries"],"metadata":{"id":"N9ANvkNe0Eqo"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_1v7SYz13Qm","executionInfo":{"status":"ok","timestamp":1646305618256,"user_tz":-60,"elapsed":3410,"user":{"displayName":"Matteo Cesaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16924188894918542260"}},"outputId":"9dc327a4-b1ac-4ac0-cac9-d41043673031"},"source":["#Text preprocessing\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","#File managing\n","import glob\n","import csv\n","import re\n","import pandas as pd\n","import string\n","\n","#GENRE\n","import pickle\n","from genre.trie import Trie\n","from genre.fairseq_model import GENRE"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"3hinUe-HVek9"},"source":["# Preprocessing"]},{"cell_type":"markdown","source":["``Disambiguation with genre``: This allows you to recognize the actual words used in the context of climate change. \n","Thanks to GENRE we obtain, for each word to be disambiguated, a list of associated entities, ordered by confidence score.\n","An appropriate threshold for acceptance of associated entities by Genre was identified through manual validation.\n","We obtain an average coefficient of -1.6 used to define our confidence threshold."],"metadata":{"id":"7FV3SKpiK4JS"}},{"cell_type":"code","metadata":{"id":"Kl1G1yt0b-OV"},"source":["def GENRE_disambiguation(df_wlp, word_to_disambiguate):\n","\n","  word_to_disambiguate_low = word_to_disambiguate.lower()\n","  #new index\n","  df_wlp[\"id\"] = range(0,len(df_wlp))\n","  df_wlp.set_index(\"id\", inplace=True)\n","\n","  #Occurrences of the word to disambiguate\n","  idx = df_wlp.index[df_wlp[\"lemma\"] == word_to_disambiguate_low]\n","\n","  #Extracting sentences from . to . that contain the word to disambiguate\n","  for id in idx:\n","\n","    start = id\n","    while (df_wlp.loc[start][\"lemma\"] != \".\"):\n","      start-=1\n","    start = start+1\n","\n","    end = id\n","    while (df_wlp.loc[end][\"lemma\"] != \".\"):\n","      end+=1\n","    end = end-1\n","\n","    #I get the raw phrase\n","    raw_text = df_wlp.loc[start:end][\"word\"].str.cat(sep=' ')\n","    #print(\"RAW_TEXT\",raw_text)\n","\n","    check = False\n","    #I prepare the raw phrase for GENRE by inserting the delimiters\n","    if word_to_disambiguate_low == \"climate\":\n","      check = re.findall(\"climate change\", raw_text, re.IGNORECASE) #e.g. I have to disambiguate climate. BUT if I already have climate change, there's no point in disambiguating, because then I will subsequently\n","    #create word phrase by inserting the hyphen, without even running the risk that GENRE may not recognize it.\n","\n","    if word_to_disambiguate_low == \"warming\":\n","      check = re.findall(\"global warming\", raw_text, re.IGNORECASE)\n","\n","    if not check: #if I didn't find it, so in the example I have only climate without change below, then I have to disambiguate. The same should be done for global warming for example.                                                \n","      tmp = df_wlp.loc[id, \"word\"]\n","      rgx = f\"({tmp})\" \n","      input_GENRE = re.sub(rgx, \"[START_ENT]\\\\1[END_ENT]\", raw_text)\n","      #print(\"MODIFIED\", input_GENRE)\n","      #print(\"--\")\n","      output_GENRE = model.sample(input_GENRE,prefix_allowed_tokens_fn=lambda batch_id, sent: trie.get(sent.tolist()),)\n","\n","      #I take the results within a certain confidence (I get a list of entities, sorted by confidence, within a certain threshold)\n","      entities_confident = [res[\"text\"].lower() for res in output_GENRE if res[\"score\"].item() > -1.6]\n","\n","      \n","      #Disambiguiation with GENRE\n","      #GENRE -> according to the fixed result label ex: for climate the label will be climate-change\n","      if entities_confident: #if the list is not empty\n","        #print(tmp, output_GENRE)\n","        label = df_wlp.loc[id][\"lemma\"]\n","        if word_to_disambiguate_low == \"climate\":\n","          if ((\"climate change\" in entities_confident) | (\"global warming\" in entities_confident)):\n","            label = \"climate-change\"\n","          \n","        if word_to_disambiguate_low == \"warming\":\n","          if ((\"climate change\" in entities_confident) | (\"global warming\" in entities_confident)| (\"human impact on the environment\" in entities_confident)):\n","            label = \"global-warming\"\n","        \n","        if word_to_disambiguate_low == \"pollution\":\n","          if ((\"human impact on the environment\" in entities_confident) | (\"air pollution\" in entities_confident) | (\"marine pollution\" in entities_confident) | (\"greenhouse gas\" in entities_confident) | (\"water pollution\" in entities_confident)):\n","            label = \"pollution_climate-change\"\n","\n","        if word_to_disambiguate_low == \"emission\":\n","          if ((\"air pollution\" in entities_confident) | (\"greenhouse gas\" in entities_confident) | (\"carbon dioxide in carth's atmosphere\" in entities_confident) | (\"exhaust gas\" in entities_confident)):\n","            label = \"emission_climate-change\"\n","        \n","        if word_to_disambiguate_low == \"temperature\":\n","          if ((\"atmosphere of earth\" in entities_confident) | (\"atmospheric temperature\" in entities_confident)):\n","            label = \"temperature_climate-change\"\n","      \n","        #I replace or concatenate the word to be disambiguated with the entity given back by GENRE  \n","        df_wlp.loc[id, \"lemma\"] = label\n","  return df_wlp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["``Preprocessing``:\n","\n","\n","*   Lemmatization\n","*   Removing the html tag\n","*   Removing punctuations\n","*   Removing stop-words\n","*   Normalization\n"],"metadata":{"id":"3RV4kdMILk-C"}},{"cell_type":"code","metadata":{"id":"_xhyTNA9eV_p"},"source":["def pre_processing(files_list, stop_words_set, word_phrases, words_to_disambiguate):\n","  string_punct_list = [char for char in string.punctuation]\n","  files_list.sort()\n","  full_preproc = str()\n","\n","  for i in range(0, len(files_list)):\n","\n","    #Un file alla volta per motivi computazionali\n","    print(f\"Appending file {files_list[i]}\")\n","\n","    #Leggo df\n","    df = pd.read_csv(files_list[i], sep = \"\\t\", names = [\"word\", \"lemma\", \"pos\"], quoting=csv.QUOTE_NONE, encoding = \"unicode_escape\")\n","\n","    #Tolgo i tag html\n","    df = df[(df[\"word\"] != \"<p>\")]\n","\n","    #Disambiguazione\n","    \n","    for word in words_to_disambiguate:\n","      df = GENRE_disambiguation(df, word)\n","    \n","    #Pulizia/Rimozione punteggiatura, stopwords ecc..\n","    df = df[(df[\"pos\"] != \"y\") & (df[\"pos\"] != \"ge\")& (df[\"pos\"] != \"...\")] #ge -> genitivo sassone\n","    df.loc[df[\"lemma\"] == \"n't\", \"lemma\"] = \"not\"\n","    mask = df['lemma'].isin(string_punct_list) | df['lemma'].isin(stop_words_set)\n","    df = df[~mask]\n","\n","    #Appending\n","    full_preproc += df[\"lemma\"].str.cat(sep=' ')\n","\n","    del df\n","    #del mask\n","  \n","  #Concat word-phrases\n","  for wp in word_phrases:\n","    full_preproc = re.sub(wp, \"\\\\1-\\\\2\", full_preproc)\n","    \n","  return full_preproc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e12LKoHAUUlU"},"source":["# Newspapers preprocessing and disambiguation \n"]},{"cell_type":"code","metadata":{"id":"3KdGAPVqEoJc"},"source":["files_newsppr_wlp = [f for f in glob.glob(\"/.../wlp_news_znw*/*.txt\")]\n","files_newsppr_wlp.sort()\n","files_newsppr_wlp"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["years = range(1990,2020,1)\n","j = 0\n","for i in range(0, len(files_newsppr_wlp)):\n","  tmp_list = [files_newsppr_wlp[i]]\n","  res = pre_processing(tmp_list, stop_words, word_phrases_target, words_to_disambiguate)\n","  with open(f\"/.../news_{years[j]}.txt\", \"w\") as file:\n","    file.write(res)\n","  print(f\"news_{years[j]}.txt\")\n","  j+=1\n","  print(\"-----------------------------------------------------------\")"],"metadata":{"id":"gF5mfLosi9J-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ay3iRzxUZZd"},"source":["# Blog preprocessing and disambiguation "]},{"cell_type":"code","metadata":{"id":"D9bg4JYy1DMh"},"source":["files_blogs_wlp = [f for f in glob.glob(\"/.../wlp_blog_qie*/*.txt\")]\n","files_blogs_wlp.sort()\n","files_blogs_wlp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBgjhSvQSeOV"},"source":["years = range(1,len(files_blogs_wlp)+1,1)\n","j = 0\n","for i in range(0, len(files_blogs_wlp)):\n","  tmp_list = [files_blogs_wlp[i]]\n","  res = pre_processing(tmp_list, stop_words, word_phrases_target, words_to_disambiguate)\n","  with open(f\"/.../blog_{years[j]}.txt\", \"w\") as file:\n","    file.write(res)\n","  print(f\"blog_{years[j]}.txt\")\n","  j+=1\n","  print(\"-----------------------------------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1iwDujl2UiMU"},"source":["# Academical preprocessing and disambiguation \n"]},{"cell_type":"code","metadata":{"id":"YrjjTTk9TYAa"},"source":["files_acad_wlp = [f for f in glob.glob(\"/.../wlp_acad_vuw*/*.txt\")]\n","files_acad_wlp.sort()\n","files_acad_wlp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGIEq-HfTYAc"},"source":["years = range(1990,2020,1)\n","j = 0\n","for i in range(0, len(files_acad_wlp)):\n","  tmp_list = [files_acad_wlp[i]]\n","  res = pre_processing(tmp_list, stop_words, word_phrases_target, words_to_disambiguate)\n","  with open(f\"/.../acad_{years[j]}.txt\", \"w\") as file:\n","    file.write(res)\n","  print(f\"acad_{years[j]}.txt\")\n","  j+=1\n","  print(\"-----------------------------------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SEXXPjrBUC-f"},"source":["# Magazine preprocessing and disambiguation "]},{"cell_type":"code","metadata":{"id":"JMKKqMVCTzRM"},"source":["files_mag_wlp = [f for f in glob.glob(\"/.../wlp_mag_dhk*/*.txt\")]\n","files_mag_wlp.sort()\n","files_mag_wlp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aqlqs0UCTzRO"},"source":["years = range(1990,2020,1)\n","j = 0\n","for i in range(0, len(files_mag_wlp)):\n","  tmp_list = [files_mag_wlp[i]]\n","  res = pre_processing(tmp_list, stop_words, word_phrases_target, words_to_disambiguate)\n","  with open(f\"/.../mag_{years[j]}.txt\", \"w\") as file:\n","    file.write(res)\n","  print(f\"mag_{years[j]}.txt\")\n","  j+=1\n","  print(\"-----------------------------------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FAEcYNlRU7z8"},"source":["# Spoken preprocessing and disambiguation "]},{"cell_type":"code","metadata":{"id":"G3SGxHmmU_nF"},"source":["files_spok_wlp = [f for f in glob.glob(\"/.../wlp_spok_cud*/*.txt\")]\n","files_spok_wlp.sort()\n","files_spok_wlp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"feZ_fSLVU_nH"},"source":["years = range(1990,2020,1)\n","j = 0\n","for i in range(0, len(files_spok_wlp)):\n","  tmp_list = [files_spok_wlp[i]]\n","  res = pre_processing(tmp_list, stop_words, word_phrases_target, words_to_disambiguate)\n","  with open(f\"/.../spok_{years[j]}.txt\", \"w\") as file:\n","    file.write(res)\n","  print(f\"spok_{years[j]}.txt\")\n","  j+=1\n","  print(\"-----------------------------------------------------------\")"],"execution_count":null,"outputs":[]}]}